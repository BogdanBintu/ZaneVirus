{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca412a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ioMicro import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff914eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder= r'S:\\ZaneTrit_3_3_2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db4dd010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map all the hybes\n",
    "hybes =  glob.glob(data_folder+os.sep+'H*')\n",
    "# map all the fovs\n",
    "fovs = [os.path.basename(fl)for fl in glob.glob(hybes[0]+os.sep+'*.zarr')]\n",
    "def get_Hi(fld): \n",
    "    try: return int(os.path.basename(fld)[1:]) \n",
    "    except: return -1\n",
    "    \n",
    "hybes = np.array(hybes)[np.argsort([get_Hi(hybe) for hybe in hybes ])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "fov = fovs[20]\n",
    "fl = hybes[0]+os.sep+fov\n",
    "\n",
    "def get_two_GFP_sets(fl,hmin_fit=750,hcutoff=3000,cor_good=0.5,cor_bad=0.25,\n",
    "                     dist_cutoff_good=4,dist_cutoff_bad=20):\n",
    "    im = read_im(fl)\n",
    "    imGFP1 = np.array(im[0],dtype=np.float32) #GFP 750 half\n",
    "    imGFP2 = np.array(im[1],dtype=np.float32) #GFP cy5 half\n",
    "    #Subtract local background\n",
    "    imGFP1_ = norm_slice(imGFP1, s=30)\n",
    "    imGFP2_ = norm_slice(imGFP2, s=30)\n",
    "    #fit both GFPs\n",
    "    Xh1 = get_local_max(imGFP1_,hmin_fit,im_raw=imGFP1,delta=1,delta_fit=3)\n",
    "    Xh2 = get_local_max(imGFP2_,hmin_fit,im_raw=imGFP2,delta=1,delta_fit=3)\n",
    "    #zc-center positions in pixels for z,xc,yc,bk- minimum signal within radius,a-total sum of signal within sphere of radius 3 pixels ,habs - max brightness of local max in oridgianl image,hn - correlation with expected PSF,h- maxium brightness in the subtracted\n",
    "\n",
    "\n",
    "    hcutoff = hcutoff\n",
    "    #threshold points based on brightness (h) and correlation with PSF\n",
    "    h = Xh1[:,-1]\n",
    "    cor = Xh1[:,-2]\n",
    "    keep = (h>hcutoff)&(cor>cor_good)\n",
    "    h = Xh1[keep,-1]\n",
    "    X = Xh1[keep,:3]\n",
    "    X1 = X\n",
    "    \n",
    "    h = Xh2[:,-1]\n",
    "    cor = Xh2[:,-2]\n",
    "    keep = (h>hcutoff)&(cor>cor_good)\n",
    "    h = Xh2[keep,-1]\n",
    "    X = Xh2[keep,:3]\n",
    "    X2 = X\n",
    "    \n",
    "    \n",
    "    # find the bad points (junk) and exlcude points next to them\n",
    "    h = Xh1[:,-1]\n",
    "    cor = Xh1[:,-2]\n",
    "    keep = (h>hcutoff)&(cor<cor_bad)\n",
    "    Xbad = Xh1[keep,:3]\n",
    "    h = Xh2[:,-1]\n",
    "    cor = Xh2[:,-2]\n",
    "    keep = (h>hcutoff)&(cor<cor_bad)\n",
    "    Xbad = np.concatenate([Xbad,Xh2[keep,:3]],axis=0)\n",
    "    \n",
    "    from scipy.spatial import KDTree\n",
    "    tree1 = KDTree(X1)\n",
    "    dist,ind1 = tree1.query(X2)\n",
    "    ind2 = np.arange(len(X2))\n",
    "    keep = dist<dist_cutoff_good\n",
    "    ind1,ind2=ind1[keep],ind2[keep]\n",
    "    X1_,X2_ = X1[ind1],X2[ind2]\n",
    "    #exclude bad points\n",
    "    tree_bad = KDTree(Xbad)\n",
    "    d1,ind1=tree_bad.query(X1_)\n",
    "    d2,ind2=tree_bad.query(X2_)\n",
    "    X1f = X1_[d1>dist_cutoff_bad]\n",
    "    X2f = X2_[d1>dist_cutoff_bad]\n",
    "\n",
    "    return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
